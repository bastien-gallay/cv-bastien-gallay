# Manual Tests - Session 1

Tests manuels pour valider le fonctionnement du skill task-management.

## Session 1: task-next + Infrastructure

### Test 1: Suggestion de t√¢che basique

**Setup:** Avoir plusieurs t√¢ches "‚è≥ √Ä faire" dans `.tasks/tasks/`

**Commande:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/algorithms/priority_scorer.py
```

**Attendu:**

- Affiche "üí° Prochaine t√¢che sugg√©r√©e: [ID]"
- Affiche le top 3 des t√¢ches
- Scores d√©croissants
- Formule WSJF visible (valeur/temps)

**Status:** [x]

---

### Test 2: Aucune t√¢che disponible

**Setup:** Mettre toutes les t√¢ches en "üîÑ En cours" ou "‚úÖ Termin√©" temporairement

**Commande:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/algorithms/priority_scorer.py
```

**Attendu:**

- Message: "‚ö†Ô∏è  Aucune t√¢che en attente!"
- Pas d'erreur

**Status:** [ ]

*Note utilisateur:*

```markdown
Il est difficile de mettre toutes les t√¢ches √† "En cours" √©tant donn√© que ce sont de vraies t√¢ches. Ce serait bien de revoir ce test en cr√©ant un environnement isol√© (jouer sur les chemins dans `.claude/skills/task-management/config/paths.yml`)
```

---

### Test 3: Configuration YAML loading

**Commande:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/core/config_loader.py
```

**Attendu:**

- Charge priorities.yml (üî¥ Haute = score 10)
- Charge trigrammes.yml (7 trigrammes)
- Charge paths.yml
- "‚úÖ All configs loaded successfully!"

**Status:** [x]

---

### Test 4: File parser sur t√¢che r√©elle

**Commande:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/core/file_parser.py
```

**Attendu:**

- Parse une t√¢che de `.tasks/tasks/`
- Extrait m√©tadonn√©es (ID, Statut, Priorit√©)
- Compte sous-t√¢ches (X/Y completed)
- Extrait sections (Description, Notes)

**Status:** [ ]

*Note utilisateur:*

```markdown
Une erreur me fait penser que la commande est incompl√®te ou une config n'est pas utilis√©e, car voici ce que j'ai:

> $ uv run --with pyyaml python3 .claude/skills/task-management/scripts/core/file_parser.py
> Testing file_parser.py
> ============================================================
> ‚ùå Tasks directory not found: ../../../.tasks/tasks


```

---

### Test 5: Tests unitaires

**Commande:**

```bash
cd .claude/skills/task-management && uv run --with pytest python3 -m pytest tests/test_file_parser.py -v
```

**Attendu:**

- 7 tests passent
- test_parse_metadata_table PASSED
- test_extract_subtasks PASSED
- test_parse_task_file PASSED
- Etc.

**Status:** [x]

*Note utilisateur:*

```markdown
1. il serait mieux d'utiliser la commande `uvx pytest tests/test_file_parser.py -v`, plus courte
2. Note pour plus tard: Je suis partag√© par le fait d'ex√©cuter les tests depuis `.claude/skills/task-management`. En effet, √† la fois cela permet de garder une isolation de ces skills dans le but de les r√©utiliser, et en m√™me temps, au sein de ce projet, utiliser une "2e racine" me semble compliqu√©. (ce probl√®me est peut-√™tre li√© √† l'√©chec du test 4)
```

---

### Test 6: Output JSON

**Commande:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/algorithms/priority_scorer.py --json --top 3
```

**Attendu:**

- Output JSON valide
- Contient id, title, priority, score, breakdown
- Top 3 t√¢ches

**Status:** [x]

---

## Notes

- Tous les tests doivent √™tre ex√©cut√©s depuis la racine du projet (`/Users/bastiengallay/Dev/cv/neat-cv/`)
- Les chemins relatifs dans les configs supposent cette racine
- `uv run --with pyyaml` installe automatiquement les d√©pendances

### Tests isol√©s (sans affecter la production)

Pour tester sans modifier les vraies t√¢ches, utilisez des variables d'environnement :

```bash
# Cr√©er un r√©pertoire de test
mkdir -p .tasks/test-tasks

# Copier une t√¢che d'exemple
cp .tasks/tasks/CNT-001*.md .tasks/test-tasks/

# Ex√©cuter avec override
TASK_SYSTEM_TASKS_DIR=.tasks/test-tasks uv run --with pyyaml python3 .claude/skills/task-management/scripts/core/file_parser.py
```

Variables d'environnement disponibles :

- `TASK_SYSTEM_TASKS_DIR` - R√©pertoire des t√¢ches
- `TASK_SYSTEM_ARCHIVED_DIR` - R√©pertoire d'archives
- `TASK_SYSTEM_DASHBOARD` - Chemin vers TASKS.md

## Validation Finale

- [ ] Tous les tests manuels passent
- [ ] Aucune erreur Python
- [ ] Output conforme aux attentes
- [x] Configuration charg√©e correctement
- [x] Algorithme WSJF produit des r√©sultats coh√©rents

**Valid√© par:** _______
**Date:** _______

---

## Session 2: Core Infrastructure + Validators

### Test 7: ID Generator

**Command:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/core/id_generator.py
```

**Attendu:**

- Shows existing IDs by trigramme
- Generates next IDs for each trigramme
- Tests slug generation
- All operations succeed

**Status:** [ ]

*Note utilisateur:*

```markdown
Erreur au lancement:

Traceback (most recent call last):
  File "/Users/bastiengallay/Dev/cv/neat-cv/.claude/skills/task-management/scripts/core/id_generator.py", line 13, in <module>
    from core.config_loader import load_paths, load_trigrammes
ModuleNotFoundError: No module named 'core'

```

---

### Test 8: DoR Validator (Valid Task)

**Setup:** Have a valid task in "‚è≥ √Ä faire" status

**Command:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/validators/dor_validator.py CNT-005
```

**Attendu:**

- ‚úÖ Valid: Yes
- No error-level issues
- May have warnings (acceptable)

**Status:** [x]

*Note utilisateur:*

```markdown
Il faudrait pouvoir faire ce teste de mani√®re isol√© de l'environnement de prod.
```

---

### Test 9: DoR Validator (Invalid Task)

**Setup:** Try with a task that's "üîÑ En cours"

**Command:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/validators/dor_validator.py <TASK-IN-PROGRESS>
```

**Attendu:**

- ‚ùå Valid: No
- Error: "Task already in progress"

**Status:** [x]

*Note utilisateur:*

```markdown
Il faudrait pouvoir faire ce teste de mani√®re isol√© de l'environnement de prod.
```

---

### Test 10: DoD Validator (In Progress Task)

**Setup:** Have a task in "üîÑ En cours" with all subtasks checked

**Command:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/validators/dod_validator.py INF-004
```

**Attendu:**

- Shows validation results
- Checks status, subtasks, result section
- Exit code 0 if valid, 1 if invalid

**Status:** [x]

*Note utilisateur:*

```markdown
Il faudrait pouvoir faire ce teste de mani√®re isol√© de l'environnement de prod.
```

---

### Test 11: Dashboard Updater

**Command:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/core/dashboard_updater.py
```

**Attendu:**

- Reads TASKS.md successfully
- Shows count of active/completed tasks
- No errors

**Status:** [ ]

*Note utilisateur:*

```markdown
Erreur au lancement:

Traceback (most recent call last):
  File "/Users/bastiengallay/Dev/cv/neat-cv/.claude/skills/task-management/scripts/core/dashboard_updater.py", line 12, in <module>
    from .config_loader import load_paths
ImportError: attempted relative import with no known parent package

```

---

### Test 12: Git Operations

**Command:**

```bash
uv run --with pyyaml python3 .claude/skills/task-management/scripts/core/git_operations.py
```

**Attendu:**

- Shows current branch
- Shows if uncommitted changes
- Formats commit message correctly

**Status:** [ ]

*Note utilisateur:*

```markdown
Erreur au lancement:

Traceback (most recent call last):
  File "/Users/bastiengallay/Dev/cv/neat-cv/.claude/skills/task-management/scripts/core/git_operations.py", line 12, in <module>
    from .config_loader import load_paths
ImportError: attempted relative import with no known parent package

```

---

### Test 13: Unit Tests (ID Generator)

**Command:**

```bash
cd .claude/skills/task-management && uvx --with pyyaml pytest tests/test_id_generator.py -v
```

**Attendu:**

- 25 tests pass
- No failures

**Status:** [x]

---

### Test 14: Unit Tests (DoR Validator)

**Command:**

```bash
cd .claude/skills/task-management && uvx --with pyyaml pytest tests/test_dor_validator.py -v
```

**Attendu:**

- 23 tests pass
- No failures

**Status:** [x]

---

## Validation Finale Session 2

- [ ] All Session 1 tests still pass
- [ ] All Session 2 manual tests pass
- [ ] ID generator works correctly
- [ ] DoR validator catches invalid states
- [ ] DoD validator validates completion criteria
- [ ] Dashboard operations work
- [ ] Git operations work
- [ ] All unit tests pass

**Valid√© par:** _______
**Date:** _______
